{"cells":[{"cell_type":"markdown","metadata":{"id":"Xp3LTq59E8UK"},"source":["# Document Clustering and Topic Modeling "]},{"cell_type":"markdown","metadata":{"id":"ZE7Qr-ccE8UN"},"source":["## Contents"]},{"cell_type":"markdown","metadata":{"id":"2S0waFW9E8UO"},"source":["* [Part 1: Data Preview](#Part-1:-Data-Preview)\n","* [Part 2: Text Preprocessing ](#Part-2:-Text-Preprocessing)\n","* [Part 3: Topic Modeling with K-Means and LDA ](#Part-3:-Topic-Modeling)\n","\n","__*Dataset:*__<br> [E-Commerce Review Data](https://s3.amazonaws.com/amazon-reviews-pds/readme.html)\n"]},{"cell_type":"markdown","metadata":{"id":"Nc9DK62BE8UP"},"source":["# Part 1: Data Preview "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2234,"status":"ok","timestamp":1634006161089,"user":{"displayName":"Chow","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10169650412261097585"},"user_tz":420},"id":"OjdBV8gGE8UQ","outputId":"2013fe14-94e9-4665-d8d5-f58625985984"},"outputs":[{"name":"stdout","output_type":"stream","text":["✔️ Libraries Imported!\n"]}],"source":["# for data exploration\n","import pandas as pd\n","import numpy as np\n","import datetime as dt \n","\n","# remove warnings \n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.filterwarnings(\"ignore\")\n","\n","# for text processing \n","import re\n","import nltk \n","\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import string \n","string.punctuation\n","\n","from bs4 import BeautifulSoup\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n","from wordcloud import WordCloud,STOPWORDS, ImageColorGenerator\n","\n","# gensim for LDA\n","import gensim\n","import gensim.corpora as corpora\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","\n","# plotting tools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as ex\n","from plotly.subplots import make_subplots\n","import pyLDAvis\n","# import pyLDAvis.gensim #dont skip this\n","import pyLDAvis.gensim_models\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","print('✔️ Libraries Imported!')"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 Understand the Raw Dataset and Data Selection"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6775,"status":"ok","timestamp":1634006213250,"user":{"displayName":"Chow","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10169650412261097585"},"user_tz":420},"id":"sIj2Z8T70FZD","outputId":"5ea4bf67-fd3e-488c-e69b-01dbf9d68e32"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","b'Skipping line 8704: expected 15 fields, saw 22\\nSkipping line 16933: expected 15 fields, saw 22\\nSkipping line 23726: expected 15 fields, saw 22\\n'\n","b'Skipping line 85637: expected 15 fields, saw 22\\n'\n","b'Skipping line 132136: expected 15 fields, saw 22\\nSkipping line 158070: expected 15 fields, saw 22\\nSkipping line 166007: expected 15 fields, saw 22\\nSkipping line 171877: expected 15 fields, saw 22\\nSkipping line 177756: expected 15 fields, saw 22\\nSkipping line 181773: expected 15 fields, saw 22\\nSkipping line 191085: expected 15 fields, saw 22\\nSkipping line 196273: expected 15 fields, saw 22\\nSkipping line 196331: expected 15 fields, saw 22\\n'\n","b'Skipping line 197000: expected 15 fields, saw 22\\nSkipping line 197011: expected 15 fields, saw 22\\nSkipping line 197432: expected 15 fields, saw 22\\nSkipping line 208016: expected 15 fields, saw 22\\nSkipping line 214110: expected 15 fields, saw 22\\nSkipping line 244328: expected 15 fields, saw 22\\nSkipping line 248519: expected 15 fields, saw 22\\nSkipping line 254936: expected 15 fields, saw 22\\n'\n","b'Skipping line 272057: expected 15 fields, saw 22\\nSkipping line 293214: expected 15 fields, saw 22\\nSkipping line 310507: expected 15 fields, saw 22\\nSkipping line 312306: expected 15 fields, saw 22\\nSkipping line 316296: expected 15 fields, saw 22\\n'\n","b'Skipping line 336028: expected 15 fields, saw 22\\nSkipping line 344885: expected 15 fields, saw 22\\nSkipping line 352551: expected 15 fields, saw 22\\n'\n","b'Skipping line 408773: expected 15 fields, saw 22\\nSkipping line 434535: expected 15 fields, saw 22\\n'\n","b'Skipping line 581593: expected 15 fields, saw 22\\n'\n","b'Skipping line 652409: expected 15 fields, saw 22\\n'\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>marketplace</th>\n","      <th>customer_id</th>\n","      <th>review_id</th>\n","      <th>product_id</th>\n","      <th>product_parent</th>\n","      <th>product_title</th>\n","      <th>product_category</th>\n","      <th>star_rating</th>\n","      <th>helpful_votes</th>\n","      <th>total_votes</th>\n","      <th>vine</th>\n","      <th>verified_purchase</th>\n","      <th>review_headline</th>\n","      <th>review_body</th>\n","      <th>review_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>US</td>\n","      <td>3653882</td>\n","      <td>R3O9SGZBVQBV76</td>\n","      <td>B00FALQ1ZC</td>\n","      <td>937001370</td>\n","      <td>Invicta Women's 15150 \"Angel\" 18k Yellow Gold ...</td>\n","      <td>Watches</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Five Stars</td>\n","      <td>Absolutely love this watch! Get compliments al...</td>\n","      <td>2015-08-31</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>US</td>\n","      <td>14661224</td>\n","      <td>RKH8BNC3L5DLF</td>\n","      <td>B00D3RGO20</td>\n","      <td>484010722</td>\n","      <td>Kenneth Cole New York Women's KC4944 Automatic...</td>\n","      <td>Watches</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>I love thiswatch it keeps time wonderfully</td>\n","      <td>I love this watch it keeps time wonderfully.</td>\n","      <td>2015-08-31</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>US</td>\n","      <td>27324930</td>\n","      <td>R2HLE8WKZSU3NL</td>\n","      <td>B00DKYC7TK</td>\n","      <td>361166390</td>\n","      <td>Ritche 22mm Black Stainless Steel Bracelet Wat...</td>\n","      <td>Watches</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Two Stars</td>\n","      <td>Scratches</td>\n","      <td>2015-08-31</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  marketplace  customer_id       review_id  product_id  product_parent  \\\n","0          US      3653882  R3O9SGZBVQBV76  B00FALQ1ZC       937001370   \n","1          US     14661224   RKH8BNC3L5DLF  B00D3RGO20       484010722   \n","2          US     27324930  R2HLE8WKZSU3NL  B00DKYC7TK       361166390   \n","\n","                                       product_title product_category  \\\n","0  Invicta Women's 15150 \"Angel\" 18k Yellow Gold ...          Watches   \n","1  Kenneth Cole New York Women's KC4944 Automatic...          Watches   \n","2  Ritche 22mm Black Stainless Steel Bracelet Wat...          Watches   \n","\n","   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n","0            5              0            0    N                 Y   \n","1            5              0            0    N                 Y   \n","2            2              1            1    N                 Y   \n","\n","                              review_headline  \\\n","0                                  Five Stars   \n","1  I love thiswatch it keeps time wonderfully   \n","2                                   Two Stars   \n","\n","                                         review_body review_date  \n","0  Absolutely love this watch! Get compliments al...  2015-08-31  \n","1       I love this watch it keeps time wonderfully.  2015-08-31  \n","2                                          Scratches  2015-08-31  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Load data into dataframe, skip the error lines\n","df = pd.read_csv('watch_reviews.tsv', sep='\\t', error_bad_lines=False)\n","df.head(3)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"name":"stdout","output_type":"stream","text":["The dataset has a time period from 2001 to 2015, in total of 5261 days 00:00:00.\n"]}],"source":["# check for the time range of the dataset\n","time_range=pd.Series(pd.to_datetime((df.review_date.sort_values(ascending=False)))).dropna()\n","time_diff=(time_range.iloc[0]-time_range.iloc[-1])\n","\n","print(f'The dataset has a time period from {time_range.iloc[-1].year} to {time_range.iloc[0].year}, in total of {time_diff}.')\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset contains 960204 rows and 15 columns.\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["# check the dataset size and number of features \n","print(f'Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["# convert the data type\n","df['review_body'] = df['review_body'].astype('string')"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2 Building Up Text Corpus"]},{"cell_type":"markdown","metadata":{},"source":["Due to the CPU limit, here we define the product that have over 300 reveiews as `popular products`, and we would only continue the data cleaning and processing on these set of data due to the limitation of memory and computation power. <br><br>\n","And since there's only 16 missing reviews out of the whole 13.24k datapoints, here we directly drop the missing values."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"name":"stdout","output_type":"stream","text":["Number of datapoints matching the criteria is: 132407\n"]},{"data":{"text/plain":["marketplace           0\n","customer_id           0\n","review_id             0\n","product_id            0\n","product_parent        0\n","product_title         0\n","product_category      0\n","star_rating           0\n","helpful_votes         0\n","total_votes           0\n","vine                  0\n","verified_purchase     0\n","review_headline       0\n","review_body          16\n","review_date           0\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# groupby's filter is the equivalent of SQL's GroupBy-Having\n","popular_products = df.groupby(df['product_id']).filter(lambda x: x['review_id'].count() >= 300)\n","\n","print(f'Number of datapoints matching the criteria is: {len(popular_products)}')\n","\n","# check for the null values for the new dataset \n","popular_products.isnull().sum()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"aoRSRJzZA7eT"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>38</th>\n","      <td>This is now my everyday watch.  Easy to read w...</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>Have worn it constantly, love the light at night</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Great product . Love the continous innovation ...</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>Alrighty, after seeking out the ultimate low-p...</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>Man watch for woman, just a right size and des...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          review_body\n","38  This is now my everyday watch.  Easy to read w...\n","44   Have worn it constantly, love the light at night\n","46  Great product . Love the continous innovation ...\n","57  Alrighty, after seeking out the ultimate low-p...\n","65  Man watch for woman, just a right size and des..."]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# seperate the `review body` out and transform to list for nlp processing\n","popular_products = popular_products.dropna(subset=['review_body'])['review_body']\n","\n","# a snippet of text \n","data = pd.DataFrame(popular_products)\n","data[5:10]"]},{"cell_type":"markdown","metadata":{},"source":["# Part 2: Text Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["## Text preprocessing/cleaning steps:\n","\n","1. *Lower Casing*\n","    - The idea is to convert the input text into same casing format so that 'text', 'Text' and 'TEXT' are treated the same way.\n","    - Pros: More helpful for text featurization like frequency, TF-IDF as it reducing the duplicates. \n","    - Cons: May not be helpful in __*sentiment analysis*__ when upper cases often refers to anger.\n","    <br><br>\n","2. [Removal of Punctuation](https://datagy.io/python-remove-punctuation-from-string/)\n","    - The `string.punctuation` in Python contains the following punctuations: <br>\n","        - !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n","    <br><br>\n","3. *Removal of Stopwords*\n","    - The commonly occuring words in a language that doesn't provides valuable information.\n","    <br><br>\n","4. *Stemming* \n","    - Convert words to it's word stem, base or root. Porter Stemmer is for English language. If we are working with other languages, we can use `snowball stemmer`. \n","    <br><br>\n","5. *Lemmatization* \n","    - Convert the word to it's original form based on its context, slower but more linguistic revalent.\n","    - _NLTK_, _Stanford_, _Bitext_ Lemmatizer available.\n","    <br><br> \n","6. *Removal of emojis*\n","    - For social media text corpuses, an explosion usage of emoji should also be taken care of. Functions credit to [this repo](https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b).\n","    - For sentiment analysis or similar purposes, the emotion delivered from emojis are unnegligible, and thanks to [this repo](https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py), we can make use this dictionary to conver the emojis to corresponding words.    \n","    - For this project's purposes, since the data ends in 2015 and not as abundant emojis are available by then, we can skip this part of preprocessing. \n","    <br><br>\n","7. *Removal of URLs* \n","    - When doing Twitter/Reddit analysis, there's good chance of having URLs present in data, we might need to remove it for analysis.\n","    <br><br> \n","8. *Removal of HTML tags*\n","    - When data is scrapped from websites, we might end up having html strings as part of the text. Can remove it by using Regex or a more elegant way of using BeautifulSoup."]},{"cell_type":"markdown","metadata":{},"source":["## 2.1 Stemming "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["def clean_text_stemming(var):\n","    \"\"\"\n","    Function for text preprocessing with Poter Stemming.\n","    \"\"\"\n","    sw = set(stopwords.words('english'))\n","    ps = PorterStemmer() \n","\n","    # tokenize the word using nltk  \n","    my_text = nltk.word_tokenize(var)\n","    \n","    # remove not english characters, lower case and remove the white apace at end \n","    my_text = re.sub('[^A-Za-z0-9]+', \" \", var).lower().strip()\n","\n","    # remove the stop words \n","    my_text = [word for word in my_text.split() if word not in sw]\n","\n","    # stemming\n","    my_text = [ps.stem(word) for word in my_text]\n","\n","    # removal of URLs\n","    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n","    my_text = url_pattern.sub(r'', ' '.join(my_text))\n","\n","    # removal of HTML Tags\n","    my_text = BeautifulSoup(my_text, \"lxml\").text\n","\n","    # convert the text to list as the vectorized words  \n","    my_text = my_text.split(\" \")\n","    \n","    return my_text"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/plain":["375                [love, comfort, feel, weak, bracelet]\n","377                                       [excel, watch]\n","382          [exactli, need, want, awesom, great, price]\n","398    [seem, cheap, watch, accur, time, keep, possib...\n","400    [ok, watch, day, easili, say, best, cheapli, p...\n","409      [excel, son, love, want, swim, yet, pass, test]\n","450                                       [pretti, good]\n","453    [great, watch, great, water, resist, substanti...\n","497                                         [niec, love]\n","513    [recommend, watch, high, qualiti, perform, adv...\n","Name: review_body, dtype: object"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["a = data['review_body'][50:60]\n","a.apply(lambda x: clean_text_stemming(x))"]},{"cell_type":"markdown","metadata":{},"source":["We can see that words like _someone_ and _compare_ have their _e_ at the end chopped off due to stemming. This is not intented, and we can use Lemmatization in such cases."]},{"cell_type":"markdown","metadata":{},"source":["## 2.2 Lemmatization "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["def clean_text_lemma(var):\n","    \"\"\"\n","    Function for text preprocessing with Lemmatizing with POS tag.\n","    \"\"\"\n","    sw = set(stopwords.words('english'))\n","    lemmatizer = WordNetLemmatizer()\n","    wordnet_map = {\"N\": wordnet.NOUN,\"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n","    \n","    # tokenize the word using nltk  \n","    my_text = nltk.word_tokenize(var)\n","    \n","    # remove not english characters, lower case and split the text \n","    my_text = re.sub('[^A-Za-z0-9]+', \" \", var).lower().strip() \n","\n","    # remove the stop words \n","    my_text = [word for word in my_text.split() if word not in sw]\n","\n","    # lemmatizing \n","    pos_tagged_text = nltk.pos_tag(my_text) \n","    my_text = \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n","\n","    # removal of URLs\n","    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n","    my_text = url_pattern.sub(r'', my_text)\n","\n","    # removal of HTML Tags\n","    my_text = BeautifulSoup(my_text, \"lxml\").text\n","\n","    # convert the text to list as the vectorized words  \n","    my_text = my_text.split(\" \")\n","\n","    return my_text"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/plain":["375            [love, comfortable, feel, weak, bracelet]\n","377                                   [excellent, watch]\n","382         [exactly, need, want, awesome, great, price]\n","398    [seem, cheap, watch, accurate, time, keep, pos...\n","400    [ok, watch, day, easily, say, best, cheaply, p...\n","409    [excellent, son, love, want, swim, yet, pass, ...\n","450                                       [pretty, good]\n","453    [great, watch, great, water, resistance, subst...\n","497                                        [niece, love]\n","513    [recommend, watch, high, quality, perform, adv...\n","Name: review_body, dtype: object"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["b = data['review_body'][50:60]\n","b.apply(lambda var: clean_text_lemma(var))\n"]},{"cell_type":"markdown","metadata":{},"source":["The experiment above shows that words are more revelant to their original meaning when lemmatizing is applied. Therefoer we would use the `clean_text_lemma` function for the whole text transformation. "]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"QAWdFqL5E8Uo"},"source":["## 2.3 TF-IDF Tokenization"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":807,"status":"ok","timestamp":1634007004369,"user":{"displayName":"Chow","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10169650412261097585"},"user_tz":420},"id":"k-XH7R4pE8Up","outputId":"04a89424-0dab-4a8d-afbd-5be23b902723"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"name":"stdout","output_type":"stream","text":["In total, there are 132391 reviews and 387 terms.\n"]}],"source":["tfidf_model = TfidfVectorizer(max_df=0.99,\n","                              max_features=1000, # normally wouldn't exited this range\n","                              min_df=0.01, \n","                              stop_words='english',\n","                              use_idf=True,\n","                              tokenizer=clean_text_lemma,\n","                              ngram_range=(1,3)) # 1-gram, 2-gram, 3-gram included \n","\n","tfidf_matrix = tfidf_model.fit_transform(data['review_body']) #fit the vectorizer to synopses\n","\n","print (\"In total, there are \" + str(tfidf_matrix.shape[0]) + \\\n","      \" reviews and \" + str(tfidf_matrix.shape[1]) + \" terms.\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"lLdKk6n-E8Uw"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/plain":["['worth', 'wrist', 'wrong', 'year', 'year ago', 'year old', 'zone']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# save the terms identified by TF-IDF and have a look \n","tf_selected_words = tfidf_model.get_feature_names()\n","\n","# print out word snippet \n","tf_selected_words[380:]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/plain":["matrix([[0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n","         0.       ],\n","        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n","         0.       ],\n","        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n","         0.       ],\n","        ...,\n","        [0.       , 0.       , 0.       , ..., 0.       , 0.2626663,\n","         0.       ],\n","        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n","         0.       ],\n","        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n","         0.       ]])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["tfidf_matrix.todense()"]},{"cell_type":"markdown","metadata":{},"source":["Now as the text has been transformed into numbers in a way that machine learning algorithm can understand, which is the process as _**text vectorization**_, we can feed the TF-IDF score to algorithms for more interesting exploration. "]},{"cell_type":"markdown","metadata":{"id":"XEcwtws5E8U8"},"source":["# Part 3: Topic Modeling\n","\n","Both K-means and Latent Dirichlet Allocation (LDA) are **unsupervised** **learning** algorithms, where the user needs to decide a priori the parameter *K*, respectively the number of clusters and the number of topics.\n","\n","If both are applied to assign *K* topics to a set of *N* documents, the most evident difference is that K-means is going to **partition** the *N* documents in *K* **disjoint** clusters (*i.e.* topics in this case). \n","\n","On the other hand, LDA assigns a document to a **mixture** of topics. Therefore each document is characterized by **one or more** topics (e.g. *Document D belongs for 60% to Topic A, 30% to topic B and 10% to topic E)*. Hence, LDA can give *more realistic results* than k-means for topic assignment."]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 K-Means Clustering"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1.1 Implementation"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"7LJQ5i3IE8U9","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["# k-means clustering\n","from sklearn.cluster import KMeans\n","\n","# initialize with 5 clusters\n","num_clusters = 5\n","km = KMeans(n_clusters=num_clusters).fit(tfidf_matrix)\n","\n","clusters = km.labels_.tolist()"]},{"cell_type":"markdown","metadata":{"id":"fboVpRAfE8U-"},"source":["### 3.1.2 Analyze K-means Result"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"KGs4aIIME8U_"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["# create DataFrame films from all of the input files.\n","product = { 'review': data['review_body'], 'cluster': clusters}\n","frame = pd.DataFrame(product, columns = ['review', 'cluster'])"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1634008119609,"user":{"displayName":"Chow","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10169650412261097585"},"user_tz":420},"id":"APmEUmm6E8VC","outputId":"6be6cbc0-44ad-4373-de07-32aa70d1b834"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>cluster</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>Scratches</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>It works well on me. However, I found cheaper ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>It works well with nice simple look.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>This watch is a very beautiful time piece. Thi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Awesome watch for the price</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>This is now my everyday watch.  Easy to read w...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>Have worn it constantly, love the light at night</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Great product . Love the continous innovation ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>Alrighty, after seeking out the ultimate low-p...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>Man watch for woman, just a right size and des...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               review  cluster\n","2                                           Scratches        3\n","3   It works well on me. However, I found cheaper ...        3\n","26               It works well with nice simple look.        3\n","29  This watch is a very beautiful time piece. Thi...        1\n","34                        Awesome watch for the price        3\n","38  This is now my everyday watch.  Easy to read w...        0\n","44   Have worn it constantly, love the light at night        0\n","46  Great product . Love the continous innovation ...        3\n","57  Alrighty, after seeking out the ultimate low-p...        1\n","65  Man watch for woman, just a right size and des...        3"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["frame.head(10)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1634008121090,"user":{"displayName":"Chow","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10169650412261097585"},"user_tz":420},"id":"Ht1SbbOSE8VE","outputId":"6f2c76b6-ca37-449a-b424-b9dca197ef4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of reviews included in each cluster:\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cluster</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>87700</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15589</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>12126</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11743</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5233</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   cluster\n","3    87700\n","2    15589\n","0    12126\n","1    11743\n","4     5233"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["print (\"Number of reviews included in each cluster:\")\n","frame['cluster'].value_counts().to_frame()"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1634008123729,"user":{"displayName":"Chow","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10169650412261097585"},"user_tz":420},"id":"vrTpBeYFuIn5","outputId":"e225f691-5b1a-4710-fe0a-ca66b2075db3"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/plain":["(5, 387)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["km.cluster_centers_.shape"]},{"cell_type":"markdown","metadata":{},"source":["The assumption underpins is that using the `cluster_center_` to represent the whole cluster, and the higher the TF-IDF value is, the higher representation power of this word is. Therefore, I choose the top _**6**_ words according to their TF-IDF score to represent it's cluster. And see if there's some pattern that we can find from it's clustering result. "]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1634008139630,"user":{"displayName":"Chow","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10169650412261097585"},"user_tz":420},"id":"tQg0CF11chKK","outputId":"9c4788b6-e293-46d0-ee7f-532b571d591a"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"name":"stdout","output_type":"stream","text":["Cluster 0 words:love,love watch,watch,gift,buy,husband,\n","Cluster 0 reviews (12126 reviews)\n","\n","Cluster 1 words:br,br br,watch,time,look,band,\n","Cluster 1 reviews (11743 reviews)\n","\n","Cluster 2 words:great,watch,great watch,price,look,work,\n","Cluster 2 reviews (15589 reviews)\n","\n","Cluster 3 words:watch,time,like,nice,look,work,\n","Cluster 3 reviews (87700 reviews)\n","\n","Cluster 4 words:good,product,good watch,watch,price,good price,\n","Cluster 4 reviews (5233 reviews)\n","\n"]}],"source":["# sort it in decreasing-order and get the top k items.\n","order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n","\n","Cluster_keywords_summary = {}\n","for i in range(num_clusters):\n","    print (\"Cluster \" + str(i) + \" words:\", end='')\n","    Cluster_keywords_summary[i] = []\n","    for j in order_centroids[i, :6]: # replace 6 with n words per cluster\n","        Cluster_keywords_summary[i].append(tf_selected_words[j])\n","        print (tf_selected_words[j] + \",\", end='')\n","    print ()\n","    \n","    cluster_reviews = frame[frame.cluster==i].review.tolist()\n","    print (\"Cluster \" + str(i) + \" reviews (\" + str(len(cluster_reviews)) + \" reviews)\")\n","    print ()"]},{"cell_type":"markdown","metadata":{},"source":["__*Analysis for the K-means clustering results:*__ <br>\n","\n","From the above clustering results, we can see that the word `watch` is showing up in each ranking, which is not surprising but redundant this case, for the model imporvement, we could add this domain related word into the stopwords. <br><br>\n","Most reviews fell into the _cluster 5_ with a ratio of 66.24%, yet the tokenized word from it is not so informative, as it just praising the punctuality of the watch. <br><br>\n","\n","_**Business Insight**_\n","\n","Cluster 0 though, with the words like `love`, `gift`, `husband` gathering, we can infer that this watch have being giving out as present to the customer's spouse and as a way of showing their affection. \n","I would suggest the brand to have some promotion activities when it comes to Vlentine's Day, and can run an A/B test on whether the promotion would help increase the sales. "]},{"cell_type":"markdown","metadata":{"id":"oYOZXL53E8VV"},"source":["## 3.2 Latent Dirichlet Allocation(LDA)\n","\n","Gensim's LDA requires the data in a certain format. Firstly, it needs the corpus as a dicionary of id-word mapping, where each word has a unique numeric ID. This is for computationally efficiency purposes. Secondly, it needs the corpus as a term-document frequency matrix which contains the frequency of each word in each document."]},{"cell_type":"markdown","metadata":{},"source":["### 3.2.1 Create the dictionary and corpus needed for Topic Modeling"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["# process all the data using lemmatization\n","data_lemmatized = data['review_body'].apply(lambda x: clean_text_lemma(x))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"name":"stdout","output_type":"stream","text":["[(8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]\n"]}],"source":["# create dictionary\n","id2word=corpora.Dictionary(data_lemmatized)\n","\n","#create corpus with Term Document Frequency\n","corpus=[id2word.doc2bow(text) for text in data_lemmatized]\n","\n","# sample\n","print(corpus[2])"]},{"cell_type":"markdown","metadata":{},"source":["Gensim creates a unique id for each word in the document, the produced corpus shown above is a mapping of (word_id, word_frequency). <br>\n","For instance, (8,1) above implies, word id 8 occurs once in the first document. And this will be used as the input by the LDA model of Gensim. "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/plain":["[[('scratch', 1)]]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# human-readable format of corpus (term-frequency)\n","[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"]},{"cell_type":"markdown","metadata":{},"source":["Let's now build the topic model with LDA. We'll define 5 topics to start with. The hyperparameter `alpha` affects sparsity of the document-topic (theta) distributions, whose default value is 1. Similarly, the hyperparameter `eta` can also be specified, which affects the topic-word distribution's sparsity.<br>\n","`chunksize` is the number of documents to be used in each training chunk. `update_every` determines how often the model parameters should be updated and passes is the total number of training passes."]},{"cell_type":"markdown","metadata":{},"source":["### 3.2.2 Build the model and view the topics"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["# Build LDA model\n","lda_model= gensim.models.ldamodel.LdaModel(corpus = corpus,\n","                                           id2word = id2word,\n","                                           num_topics = 5,\n","                                           random_state=100,\n","                                           update_every=1,\n","                                           chunksize=100,\n","                                           passes=10,\n","                                           alpha='auto',\n","                                           per_word_topics=True)"]},{"cell_type":"markdown","metadata":{},"source":["The above LDA model is built with 5 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic. We can see the keywords for each topic and the importance(weight) of each keyword using `lda_model.print_topics()` as shown next. "]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/plain":["[(0,\n","  '0.102*\"great\" + 0.090*\"good\" + 0.076*\"work\" + 0.068*\"price\" + 0.051*\"love\" + 0.026*\"quality\" + 0.025*\"recommend\" + 0.024*\"product\" + 0.022*\"perfect\" + 0.019*\"night\"'),\n"," (1,\n","  '0.051*\"light\" + 0.043*\"feature\" + 0.042*\"read\" + 0.038*\"casio\" + 0.033*\"alarm\" + 0.031*\"see\" + 0.026*\"button\" + 0.022*\"digital\" + 0.020*\"hand\" + 0.019*\"g\"'),\n"," (2,\n","  '0.152*\"time\" + 0.045*\"set\" + 0.039*\"keep\" + 0.028*\"date\" + 0.023*\"3\" + 0.022*\"change\" + 0.021*\"clock\" + 0.016*\"accurate\" + 0.016*\"black\" + 0.015*\"receive\"'),\n"," (3,\n","  '0.056*\"br\" + 0.017*\"day\" + 0.012*\"second\" + 0.011*\"take\" + 0.011*\"first\" + 0.011*\"back\" + 0.011*\"pin\" + 0.010*\"amazon\" + 0.010*\"month\" + 0.009*\"5\"'),\n"," (4,\n","  '0.125*\"watch\" + 0.025*\"look\" + 0.023*\"band\" + 0.023*\"one\" + 0.019*\"like\" + 0.018*\"get\" + 0.016*\"buy\" + 0.015*\"use\" + 0.013*\"year\" + 0.013*\"would\"')]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# print the 5 topics\n","lda_model.print_topics()"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2.3 Model evaluation and visualization"]},{"cell_type":"markdown","metadata":{},"source":["\n","Finally we'd like to evalue how good a given model is, and normally we'd reference to coherence score. "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"name":"stdout","output_type":"stream","text":["\n","Perplexity:  -6.966787747024273\n","\n","Coherence Score: 0.4633478978096902\n"]}],"source":["# compute perplexity\n","print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n","\n","# compute coherence score\n","coherence_model_lda=CoherenceModel(model=lda_model,texts=data_lemmatized,dictionary=id2word,coherence='c_v')\n","coherence_lda=coherence_model_lda.get_coherence()\n","print('\\nCoherence Score:',coherence_lda)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/html":["\n","<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n","\n","\n","<div id=\"ldavis_el219761835231069792235503351\"></div>\n","<script type=\"text/javascript\">\n","\n","var ldavis_el219761835231069792235503351_data = {\"mdsDat\": {\"x\": [-0.3024944968022475, -0.2455067596032469, 0.18446171779602996, 0.20659236996524355, 0.1569471686442206], \"y\": [0.01201464913077568, 0.01829529944446787, -0.21412543764249112, 0.3781757333110996, -0.19436024424385193], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [46.50790872972222, 26.146673978459635, 9.301268372832892, 9.268859376327043, 8.775289542658218]}, \"tinfo\": {\"Term\": [\"watch\", \"time\", \"great\", \"good\", \"br\", \"work\", \"price\", \"love\", \"light\", \"set\", \"feature\", \"look\", \"read\", \"keep\", \"band\", \"one\", \"casio\", \"alarm\", \"like\", \"see\", \"get\", \"date\", \"buy\", \"quality\", \"recommend\", \"button\", \"day\", \"hand\", \"product\", \"3\", \"watch\", \"look\", \"band\", \"like\", \"buy\", \"year\", \"would\", \"wear\", \"well\", \"easy\", \"need\", \"wrist\", \"battery\", \"nice\", \"really\", \"also\", \"face\", \"want\", \"find\", \"small\", \"little\", \"much\", \"purchase\", \"tool\", \"think\", \"last\", \"big\", \"timex\", \"large\", \"size\", \"one\", \"get\", \"make\", \"use\", \"go\", \"br\", \"second\", \"pin\", \"back\", \"first\", \"amazon\", \"month\", \"5\", \"two\", \"strap\", \"2\", \"minute\", \"case\", \"link\", \"1\", \"review\", \"break\", \"water\", \"scratch\", \"week\", \"invicta\", \"hour\", \"4\", \"plastic\", \"put\", \"try\", \"remove\", \"star\", \"fine\", \"several\", \"day\", \"problem\", \"take\", \"run\", \"time\", \"set\", \"keep\", \"date\", \"3\", \"change\", \"clock\", \"accurate\", \"black\", \"receive\", \"though\", \"instruction\", \"turn\", \"show\", \"drive\", \"gift\", \"durable\", \"eco\", \"figure\", \"update\", \"exactly\", \"service\", \"instead\", \"arrive\", \"type\", \"mode\", \"zone\", \"check\", \"direction\", \"correct\", \"great\", \"good\", \"price\", \"love\", \"quality\", \"recommend\", \"product\", \"perfect\", \"night\", \"stop\", \"excellent\", \"actually\", \"value\", \"highly\", \"place\", \"side\", \"perfectly\", \"anyone\", \"beautiful\", \"christmas\", \"fast\", \"else\", \"friend\", \"sturdy\", \"u\", \"son\", \"absolutely\", \"strong\", \"shipping\", \"condition\", \"work\", \"e\", \"tough\", \"ship\", \"light\", \"feature\", \"read\", \"casio\", \"alarm\", \"button\", \"digital\", \"g\", \"shock\", \"display\", \"model\", \"number\", \"timer\", \"dial\", \"hard\", \"dark\", \"analog\", \"manual\", \"atomic\", \"solar\", \"indiglo\", \"bezel\", \"difficult\", \"press\", \"stopwatch\", \"dive\", \"power\", \"mean\", \"real\", \"countdown\", \"see\", \"hand\", \"old\"], \"Freq\": [193792.0, 47154.0, 31706.0, 27966.0, 48878.0, 24884.0, 21061.0, 15931.0, 14978.0, 13911.0, 12580.0, 39374.0, 12275.0, 11971.0, 36513.0, 36418.0, 11256.0, 9703.0, 29195.0, 9196.0, 28638.0, 8657.0, 25253.0, 7935.0, 7861.0, 7611.0, 15602.0, 10488.0, 7338.0, 7218.0, 193792.3123979637, 39374.07001966057, 36512.578426921056, 29195.294458498607, 25253.491934357546, 20744.806842701615, 20547.71020439547, 19988.051725475325, 18579.626510532857, 17860.766021499967, 15226.601678193163, 14687.615496063008, 14696.266457925842, 13612.404261818474, 13597.113853146226, 12300.50716817687, 12087.044177714866, 11496.343969547699, 11191.787566261894, 10927.898498250315, 10770.111784340623, 10686.125242327857, 10526.50790500624, 9816.727452809806, 9413.82388187627, 9269.038935590634, 8709.616339370998, 8506.736233502988, 7844.817538946302, 7498.361566524408, 36410.94916133005, 28609.27500244675, 16517.80910944719, 24040.645315065805, 11412.358874668065, 48877.55987994, 10904.944046486764, 9520.590791885985, 9558.64418198513, 9571.829808165552, 9031.655211502572, 8581.386457519902, 8210.784692297597, 8073.427029602904, 7711.467068618795, 7573.229116695545, 7004.286472785097, 6565.138082314928, 6436.826571128849, 6205.063990491442, 6057.152619966032, 6026.646367601365, 5978.453786641881, 5794.054753023202, 5643.087997841743, 5459.734409378973, 5276.112340837254, 5136.536869975236, 5047.450705111717, 5028.741711488902, 4772.976198217389, 4654.370241885344, 4590.836058353872, 4349.779185528822, 3702.430595653078, 15192.775114889911, 7351.016291108783, 9776.19521711013, 5366.563686223432, 47154.32107492777, 13911.500515041198, 11971.536883093377, 8657.069416420616, 7217.836339818048, 6791.863899920951, 6418.483715809659, 4984.882691604717, 4887.1460339077485, 4725.052035018198, 4647.0336384673055, 4504.186730050484, 3603.184242771215, 3543.4364441550456, 3361.1926635580185, 3289.2468118892934, 3094.0484425271006, 2877.2853323530117, 2675.170767916509, 2660.140191903236, 2617.4943258784388, 2519.643059098764, 2207.794639224348, 2070.268804772406, 2079.39165881412, 2024.4901457785388, 1986.7702996835355, 1937.5621954231904, 1628.7111214201009, 1621.2686217576577, 31706.10593500294, 27966.14062210362, 21061.238748029173, 15930.886330569636, 7935.1954647013445, 7860.712830912709, 7337.588369684202, 6939.864475868264, 5740.15630549023, 5552.753691209535, 4688.318892651952, 4011.9797538612697, 3561.9126119008724, 3184.643510019199, 3182.2110732190977, 3029.8477773778022, 2919.0591352723613, 2645.8353977129696, 2613.010767699936, 1997.606131929195, 1959.1855129154071, 1972.4612419106006, 1864.4055582018584, 1849.6577925185318, 1794.796017654024, 1764.4786664317994, 1599.5210065396122, 1615.738213235094, 1531.6812843963096, 1484.7960218130918, 23428.13992103051, 1623.2839875082086, 1729.4081998806598, 1685.557859332949, 14978.300805940968, 12579.76210714715, 12275.072591471959, 11256.23671481678, 9702.78961345951, 7611.246069581192, 6392.372233427337, 5536.562307859681, 5400.766054498415, 5361.041015356362, 5351.957168098358, 5204.616335499736, 5150.943325766325, 4963.164791967714, 4632.124801488317, 3763.1090568517043, 3391.991245859046, 2674.9161441766023, 2645.136973026997, 2594.9469967077703, 2351.946437139478, 2269.4066548260366, 2261.329818169438, 2242.971534336789, 2139.7824371573247, 1947.404502579063, 1919.2422005390608, 1939.4529961464461, 1907.7537331993697, 1812.8089892177086, 9096.808423737077, 5824.856227392813, 2597.9849576489914], \"Total\": [193792.0, 47154.0, 31706.0, 27966.0, 48878.0, 24884.0, 21061.0, 15931.0, 14978.0, 13911.0, 12580.0, 39374.0, 12275.0, 11971.0, 36513.0, 36418.0, 11256.0, 9703.0, 29195.0, 9196.0, 28638.0, 8657.0, 25253.0, 7935.0, 7861.0, 7611.0, 15602.0, 10488.0, 7338.0, 7218.0, 193792.75645905168, 39374.51350897457, 36513.02256568578, 29195.73853435043, 25253.935641800606, 20745.25175356584, 20548.154060651163, 19988.494980318188, 18580.070470842293, 17861.212346041488, 15227.046368111214, 14688.058393598616, 14696.711136298161, 13612.847748081951, 13597.557471883665, 12300.952288629704, 12087.488515095376, 11496.787953426887, 11192.232132099007, 10928.341309403666, 10770.555525846565, 10686.56908116833, 10526.951233408377, 9817.170105074478, 9414.267576248543, 9269.483498611744, 8710.059276279448, 8507.182442073414, 7845.261584450019, 7498.803353758602, 36418.959256648755, 28638.84605333959, 16732.668972973897, 26512.343023869915, 14969.174892554358, 48878.00825637585, 10905.39389746951, 9521.036784458927, 9559.092024965268, 9572.27962352228, 9032.105128364821, 8581.835820564958, 8211.234951923147, 8073.877037070167, 7711.9180944430755, 7573.678378427593, 7004.735437612956, 6565.58665772647, 6437.273325627785, 6205.513779209471, 6057.6014011964635, 6027.094666400071, 5978.902521422703, 5794.5033317010975, 5643.536361968598, 5460.182795842774, 5276.562185543753, 5136.986535224558, 5047.899741610012, 5029.1918294063635, 4773.42485936835, 4654.816666906214, 4591.2849609262075, 4350.229663380117, 3702.8824542241496, 15602.277750592497, 8291.093797710848, 12788.087412654566, 5706.78452349298, 47154.76290385093, 13911.94084983677, 11971.9793640663, 8657.512372727824, 7218.2810366239155, 6792.305712981234, 6418.92348792389, 4985.324667498375, 4887.591600903747, 4725.494017381104, 4647.478563230676, 4504.627392042508, 3603.6260720004416, 3543.8789873497626, 3361.637492036837, 3289.690308678664, 3094.49321185221, 2877.730681814705, 2675.6139349706987, 2660.5837595560197, 2617.9370139017005, 2520.087771328793, 2208.239505897742, 2070.7112949802145, 2079.8372238292873, 2024.9301269678124, 1987.2090294624904, 1938.0047194219205, 1629.152524025588, 1621.710013109089, 31706.53608183889, 27966.57210495909, 21061.66861089361, 15931.315732900104, 7935.624568999663, 7861.142223634954, 7338.016616372109, 6940.295004668814, 5740.5925294700955, 5553.187246535477, 4688.749989458345, 4012.413415533466, 3562.3426804426545, 3185.073493235994, 3182.6473360114805, 3030.283426235245, 2919.49172214656, 2646.2646839258823, 2613.4397943259673, 1998.0353413595014, 1959.6149550933408, 1972.8978608827235, 1864.836544244765, 1850.090019134574, 1795.2279863289855, 1764.904667719147, 1599.9517501125015, 1616.1733371656146, 1532.1117428166037, 1485.226662851549, 24884.007179339907, 1657.846184713852, 2348.032258313921, 2653.7316328811544, 14978.755147242638, 12580.217005883538, 12275.528508837911, 11256.689912421885, 9703.242283246493, 7611.699210343809, 6392.824463673486, 5537.012309118915, 5401.216133569393, 5361.492777522767, 5352.414244250162, 5205.0724516137425, 5151.3977817285795, 4963.620304124859, 4632.580026967579, 3763.5619865761614, 3392.4426680704614, 2675.371605548999, 2645.5877346070515, 2595.3974619384476, 2352.404500873104, 2269.8622390376354, 2261.786674200855, 2243.427039577226, 2140.234804472452, 1947.8588280716397, 1919.694165512393, 1939.9107660249742, 1908.2110749897506, 1813.2621454448356, 9196.886644324426, 10488.09805348254, 5481.944456413983], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.0817, -3.6754, -3.7508, -3.9745, -4.1195, -4.3162, -4.3257, -4.3534, -4.4264, -4.4659, -4.6254, -4.6615, -4.6609, -4.7375, -4.7386, -4.8388, -4.8564, -4.9065, -4.9333, -4.9572, -4.9717, -4.9795, -4.9946, -5.0644, -5.1063, -5.1218, -5.1841, -5.2076, -5.2886, -5.3338, -3.7536, -3.9948, -4.5441, -4.1687, -4.9138, -2.8833, -4.3834, -4.5191, -4.5151, -4.5138, -4.5719, -4.623, -4.6671, -4.684, -4.7299, -4.748, -4.8261, -4.8908, -4.9106, -4.9472, -4.9713, -4.9764, -4.9844, -5.0158, -5.0422, -5.0752, -5.1094, -5.1362, -5.1537, -5.1574, -5.2096, -5.2348, -5.2485, -5.3025, -5.4636, -4.0518, -4.7778, -4.4926, -5.0924, -1.8856, -3.1063, -3.2565, -3.5806, -3.7625, -3.8233, -3.8798, -4.1326, -4.1524, -4.1861, -4.2028, -4.234, -4.4572, -4.4739, -4.5267, -4.5484, -4.6095, -4.6822, -4.755, -4.7606, -4.7768, -4.8149, -4.947, -5.0113, -5.0069, -5.0337, -5.0525, -5.0776, -5.2512, -5.2558, -2.279, -2.4045, -2.6881, -2.9673, -3.6642, -3.6736, -3.7425, -3.7982, -3.988, -4.0212, -4.1905, -4.3462, -4.4652, -4.5772, -4.578, -4.627, -4.6643, -4.7625, -4.775, -5.0436, -5.063, -5.0562, -5.1126, -5.1205, -5.1506, -5.1677, -5.2658, -5.2557, -5.3092, -5.3402, -2.5816, -5.2511, -5.1877, -5.2134, -2.9742, -3.1487, -3.1732, -3.2599, -3.4084, -3.6512, -3.8257, -3.9694, -3.9943, -4.0016, -4.0033, -4.0313, -4.0416, -4.0788, -4.1478, -4.3556, -4.4594, -4.6969, -4.7081, -4.7272, -4.8256, -4.8613, -4.8649, -4.873, -4.9201, -5.0143, -5.0289, -5.0184, -5.0349, -5.0859, -3.4729, -3.9187, -4.7261], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7655, 0.7653, 0.7645, 0.7526, 0.6677, 0.4943, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3414, 1.3413, 1.3413, 1.3149, 1.2211, 1.0729, 1.28, 2.375, 2.375, 2.375, 2.375, 2.375, 2.375, 2.375, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3749, 2.3748, 2.3748, 2.3748, 2.3748, 2.3748, 2.3748, 2.3748, 2.3747, 2.3747, 2.3785, 2.3785, 2.3785, 2.3785, 2.3785, 2.3785, 2.3785, 2.3784, 2.3784, 2.3784, 2.3784, 2.3784, 2.3784, 2.3784, 2.3784, 2.3784, 2.3784, 2.3783, 2.3783, 2.3783, 2.3783, 2.3783, 2.3783, 2.3783, 2.3783, 2.3783, 2.3782, 2.3782, 2.3782, 2.3782, 2.3182, 2.3574, 2.0727, 1.9246, 2.4332, 2.4332, 2.4332, 2.4332, 2.4332, 2.4332, 2.4332, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.4331, 2.433, 2.433, 2.433, 2.433, 2.433, 2.433, 2.433, 2.433, 2.433, 2.433, 2.4223, 1.8451, 1.6865]}, \"token.table\": {\"Topic\": [2, 2, 3, 2, 2, 4, 3, 4, 5, 1, 2, 5, 4, 3, 5, 2, 1, 1, 4, 5, 1, 3, 2, 2, 5, 1, 2, 5, 3, 3, 4, 3, 4, 3, 5, 5, 3, 2, 3, 5, 5, 5, 3, 5, 5, 3, 3, 2, 4, 1, 3, 4, 3, 4, 1, 4, 5, 3, 1, 2, 2, 4, 5, 1, 2, 3, 1, 2, 4, 4, 2, 5, 5, 4, 2, 5, 3, 3, 2, 3, 1, 1, 5, 1, 2, 1, 1, 4, 1, 2, 5, 5, 2, 3, 5, 2, 1, 1, 1, 4, 5, 1, 5, 1, 2, 4, 4, 2, 4, 2, 5, 5, 4, 1, 2, 4, 1, 2, 4, 5, 5, 1, 3, 4, 2, 2, 1, 2, 2, 2, 1, 5, 3, 3, 2, 2, 4, 4, 5, 3, 4, 1, 1, 5, 4, 2, 4, 5, 2, 4, 4, 1, 2, 1, 3, 3, 5, 1, 1, 2, 4, 2, 3, 2, 3, 4, 3, 1, 2, 4, 1, 1, 2, 1, 2, 1, 2, 4, 1, 1, 1, 3], \"Freq\": [0.9999172060158512, 0.9999104294645618, 0.9999610659902974, 1.0000026211428334, 0.9999713865302208, 1.0000301570891093, 0.9999348753551617, 0.9998969658680071, 0.9999750306918636, 1.0000038786729009, 0.9999883605910995, 0.9998695134704477, 0.9998999782873232, 0.9996564972712813, 0.9997778434639066, 0.9999903730432735, 0.9999993819825314, 0.9999516125552468, 0.9998317182102598, 0.9996201359612022, 0.9999931945033246, 0.9998789586053716, 0.9999998310819909, 0.9999842931950946, 0.9999081400454108, 0.9999629506539544, 0.9999106465641149, 0.9999387108974972, 0.9999549912807002, 0.9999975648037008, 0.999982311944754, 0.9998561304047903, 0.9998473883769944, 0.9995621824473243, 0.9998554288217542, 0.9998506769442975, 0.9999408175575425, 0.9737680768708944, 0.026214121203198566, 0.9998750299001832, 0.9996521890371766, 0.9998710329560633, 0.9999063783020075, 0.999908089492383, 0.9995590912137663, 0.9998103626466723, 0.9998406162759313, 0.020508537108868442, 0.9789810508145143, 0.9999881113310018, 0.9997460909669823, 0.9995449025007702, 0.9996420792797058, 0.9998400449032191, 0.9999595850622927, 0.9996861857520823, 0.9999827502273262, 0.9997705442617583, 0.9999792595349822, 0.9999472066079521, 0.9999707881995431, 0.9995514114910785, 0.9999977769384953, 0.9989578472092067, 0.0010126106319363485, 0.9997901599804568, 0.7623666689655894, 0.23755484357182227, 0.9999795432576812, 0.9999830923870868, 0.4445991996090908, 0.5553914513667068, 0.9998747939670329, 0.9999769257330638, 0.999893456094331, 0.999828047908872, 0.9998915398908939, 0.99986072276619, 0.9999665220287289, 1.00000172368604, 0.9999666570136377, 0.9999478397462149, 0.9999495854471739, 0.9999747040360167, 0.9999575401549757, 0.9999484218018995, 0.9999869583410993, 0.9999801816180536, 0.9871706675533578, 0.012849115723693664, 0.9998611013332771, 0.999530511381799, 0.999895008509671, 0.999540662191043, 0.9999226060930155, 0.9999026058546873, 0.9999467480007841, 0.999996954884743, 0.9999377244131691, 0.9998967825242684, 0.9999860805753588, 0.5260907006501431, 0.47391943144558657, 0.999781452935196, 0.00021966580493481554, 0.9999574939294922, 0.999831572686838, 0.9999961365070045, 0.9997966045423393, 0.999821759215502, 0.9996383978631264, 0.9998096485556729, 0.9999682546095487, 0.1133746671952417, 0.8866140197364061, 0.9999977355772033, 1.0000046325465504, 0.9999618568126112, 0.9999212955458978, 0.9999569461439048, 0.9998893859319249, 0.9999590020571844, 0.9998954569872934, 0.9999819080191011, 0.9998245544422791, 0.9999007195824497, 0.05957820881449621, 0.9404595491394151, 0.9999131363514205, 0.9999638804913226, 0.010873244812875008, 0.9891390806272394, 0.9999651713207008, 1.0000042517549397, 0.9997616845160335, 0.3647693640178088, 0.635331764188043, 0.9999270661444065, 0.999959984276865, 0.9997519702696113, 0.9999064687372834, 0.9998928690724769, 0.9999687684165417, 0.9998468589322921, 0.9994874126995674, 0.9999379343846804, 0.9999662812494583, 0.9998902903214351, 0.9998809512196795, 0.9998927484066044, 0.9999513433759206, 0.23553170249833047, 0.7644614620264538, 0.9999715775819652, 0.9998970273398436, 0.9999838212769199, 0.9999227817875004, 0.9999785543480869, 0.9999826726976657, 0.26319910972763827, 0.7363612632994929, 0.9999109948557133, 0.9998262661031049, 0.9998913734918008, 0.9995974570414958, 0.9998730042475265, 0.9997805896717504, 0.9067851897644472, 0.09320187196489119, 0.9999038047505828, 0.9999314631677927, 0.9999960965566231, 0.9998490489819044, 0.9999752367390004, 0.9999049599516693, 0.9999962071811082, 0.05851147644776652, 0.9414882350400233, 0.9999925024578505, 0.999996024416771, 0.9999878645210561, 0.999894812543929], \"Term\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"absolutely\", \"accurate\", \"actually\", \"alarm\", \"also\", \"amazon\", \"analog\", \"anyone\", \"arrive\", \"atomic\", \"back\", \"band\", \"battery\", \"beautiful\", \"bezel\", \"big\", \"black\", \"br\", \"break\", \"button\", \"buy\", \"case\", \"casio\", \"change\", \"check\", \"christmas\", \"clock\", \"condition\", \"correct\", \"countdown\", \"dark\", \"date\", \"day\", \"day\", \"dial\", \"difficult\", \"digital\", \"direction\", \"display\", \"dive\", \"drive\", \"durable\", \"e\", \"e\", \"easy\", \"eco\", \"else\", \"exactly\", \"excellent\", \"face\", \"fast\", \"feature\", \"figure\", \"find\", \"fine\", \"first\", \"friend\", \"g\", \"get\", \"get\", \"gift\", \"go\", \"go\", \"good\", \"great\", \"hand\", \"hand\", \"hard\", \"highly\", \"hour\", \"indiglo\", \"instead\", \"instruction\", \"invicta\", \"keep\", \"large\", \"last\", \"light\", \"like\", \"link\", \"little\", \"look\", \"love\", \"make\", \"make\", \"manual\", \"mean\", \"minute\", \"mode\", \"model\", \"month\", \"much\", \"need\", \"nice\", \"night\", \"number\", \"old\", \"old\", \"one\", \"one\", \"perfect\", \"perfectly\", \"pin\", \"place\", \"plastic\", \"power\", \"press\", \"price\", \"problem\", \"problem\", \"product\", \"purchase\", \"put\", \"quality\", \"read\", \"real\", \"really\", \"receive\", \"recommend\", \"remove\", \"review\", \"run\", \"run\", \"scratch\", \"second\", \"see\", \"see\", \"service\", \"set\", \"several\", \"ship\", \"ship\", \"shipping\", \"shock\", \"show\", \"side\", \"size\", \"small\", \"solar\", \"son\", \"star\", \"stop\", \"stopwatch\", \"strap\", \"strong\", \"sturdy\", \"take\", \"take\", \"think\", \"though\", \"time\", \"timer\", \"timex\", \"tool\", \"tough\", \"tough\", \"try\", \"turn\", \"two\", \"type\", \"u\", \"update\", \"use\", \"use\", \"value\", \"want\", \"watch\", \"water\", \"wear\", \"week\", \"well\", \"work\", \"work\", \"would\", \"wrist\", \"year\", \"zone\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 4, 3, 1, 2]};\n","\n","function LDAvis_load_lib(url, callback){\n","  var s = document.createElement('script');\n","  s.src = url;\n","  s.async = true;\n","  s.onreadystatechange = s.onload = callback;\n","  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n","  document.getElementsByTagName(\"head\")[0].appendChild(s);\n","}\n","\n","if(typeof(LDAvis) !== \"undefined\"){\n","   // already loaded: just create the visualization\n","   !function(LDAvis){\n","       new LDAvis(\"#\" + \"ldavis_el219761835231069792235503351\", ldavis_el219761835231069792235503351_data);\n","   }(LDAvis);\n","}else if(typeof define === \"function\" && define.amd){\n","   // require.js is available: use it to load d3/LDAvis\n","   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n","   require([\"d3\"], function(d3){\n","      window.d3 = d3;\n","      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n","        new LDAvis(\"#\" + \"ldavis_el219761835231069792235503351\", ldavis_el219761835231069792235503351_data);\n","      });\n","    });\n","}else{\n","    // require.js not available: dynamically load d3 & LDAvis\n","    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n","         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n","                 new LDAvis(\"#\" + \"ldavis_el219761835231069792235503351\", ldavis_el219761835231069792235503351_data);\n","            })\n","         });\n","}\n","</script>"],"text/plain":["PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n","topic                                                \n","4     -0.302494  0.012015       1        1  46.507909\n","3     -0.245507  0.018295       2        1  26.146674\n","2      0.184462 -0.214125       3        1   9.301268\n","0      0.206592  0.378176       4        1   9.268859\n","1      0.156947 -0.194360       5        1   8.775290, topic_info=           Term           Freq          Total Category  logprob  loglift\n","68        watch  193792.000000  193792.000000  Default  30.0000  30.0000\n","65         time   47154.000000   47154.000000  Default  29.0000  29.0000\n","103       great   31706.000000   31706.000000  Default  28.0000  28.0000\n","36         good   27966.000000   27966.000000  Default  27.0000  27.0000\n","21           br   48878.000000   48878.000000  Default  26.0000  26.0000\n","...         ...            ...            ...      ...      ...      ...\n","597        real    1907.753733    1908.211075   Topic5  -5.0349   2.4330\n","2977  countdown    1812.808989    1813.262145   Topic5  -5.0859   2.4330\n","684         see    9096.808424    9196.886644   Topic5  -3.4729   2.4223\n","498        hand    5824.856227   10488.098053   Topic5  -3.9187   1.8451\n","317         old    2597.984958    5481.944456   Topic5  -4.7261   1.6865\n","\n","[196 rows x 6 columns], token_table=      Topic      Freq   Term\n","term                        \n","86        2  0.999917      1\n","228       2  0.999910      2\n","385       3  0.999961      3\n","469       2  1.000003      4\n","409       2  0.999971      5\n","...     ...       ...    ...\n","9         4  0.941488   work\n","187       1  0.999993  would\n","71        1  0.999996  wrist\n","151       1  0.999988   year\n","1625      3  0.999895   zone\n","\n","[182 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 4, 3, 1, 2])"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# visulaise the topics\n","pyLDAvis.enable_notebook()\n","vis=pyLDAvis.gensim_models.prepare(lda_model,corpus,id2word)\n","vis"]},{"cell_type":"markdown","metadata":{},"source":["From the pyLDAvis's output, we can see that each bubble on the left hand side represents a topic, and the larger the bubble, the more prevalent is that topic. Normally, a good topic model will have _fairly big, non-overlapping bubbles scattered throughout the chart_ instead of being clustered in one quadrant.<br><br>\n","A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart. Given our prior knowledge of the number of natural topics in the document, finding the best model was fairly straightforward, as now it seems that two bubbles on the left are largely overlapped. "]},{"cell_type":"markdown","metadata":{},"source":["### 3.2.4 Hyperparameter Tuning: Number of Topics and Alpha"]},{"cell_type":"markdown","metadata":{},"source":["The below `compute_coherence_values()` trains multiple LDA models and provides the models and their corresponding coherence scores. <br><br>\n","\n","`alpha` is a parameter that controls the _prior distribution over topic weights_ in each document, while `eta` is a parameter for the prior distribution over word weights in each topic. In gensim, both default to a symmetric, _1 / num_topics prior_.<br><br>\n","\n","These two parameters can be thought of as __*smoothing parameters*__ when we compute how much each document _\"likes\" a topic_ (in the case of alpha) or how much each topic _\"likes\" a word_ (in the case of eta). A higher alpha makes the document preferences \"smoother\" over topics, and a higher eta makes the topic preferences \"smoother\" over words.<br><br>\n","\n","Since we only have one document for this assignment, we'll focus on `alpha` for hyperparameter tuning.\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["def compute_coherence_values(dictionary, corpus, texts, num_topics_range,alpha_range):\n","    \"\"\"\n","    Compute c_v coherence for various number of topics\n","\n","    Parameters:\n","    ----------\n","    dictionary : Gensim dictionary\n","    corpus : Gensim corpus\n","    texts : List of input texts\n","    num_topics_range: A list of topics range \n","    alpha_range: A list of alpha range\n","\n","    Returns:\n","    -------\n","    model_list : List of LDA topic models\n","    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n","    \"\"\"\n","    coherence_values = []\n","    model_list = []\n","    for alpha in alpha_range:\n","        for num_topics in num_topics_range:\n","            model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, alpha=alpha,num_topics=num_topics,\\\n","                                                      per_word_topics=True)\n","            model_list.append(model)\n","            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n","            coherence_values.append((alpha, num_topics, coherencemodel.get_coherence()))\n","\n","    return model_list, coherence_values"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["# build models accross a range of num_topics and alpha(this takes a long time)\n","num_topics_range= [2,3,5,10]\n","\n","# 1 --> high, 0.1 --> original, 0.01 --> low \n","alpha_range=[0.01,0.1,1]\n","model_list, coherence_values= compute_coherence_values(dictionary=id2word,corpus=corpus,texts=data_lemmatized,\\\n","                                                       num_topics_range=num_topics_range,alpha_range=alpha_range)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alpha</th>\n","      <th>num_topics</th>\n","      <th>coherence_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.01</td>\n","      <td>2</td>\n","      <td>0.431145</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.01</td>\n","      <td>3</td>\n","      <td>0.448082</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.01</td>\n","      <td>5</td>\n","      <td>0.477359</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.01</td>\n","      <td>10</td>\n","      <td>0.479134</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.10</td>\n","      <td>2</td>\n","      <td>0.430488</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.10</td>\n","      <td>3</td>\n","      <td>0.473921</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.10</td>\n","      <td>5</td>\n","      <td>0.459109</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>0.470194</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.00</td>\n","      <td>2</td>\n","      <td>0.448637</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1.00</td>\n","      <td>3</td>\n","      <td>0.445851</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1.00</td>\n","      <td>5</td>\n","      <td>0.457845</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1.00</td>\n","      <td>10</td>\n","      <td>0.482343</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    alpha  num_topics  coherence_value\n","0    0.01           2         0.431145\n","1    0.01           3         0.448082\n","2    0.01           5         0.477359\n","3    0.01          10         0.479134\n","4    0.10           2         0.430488\n","5    0.10           3         0.473921\n","6    0.10           5         0.459109\n","7    0.10          10         0.470194\n","8    1.00           2         0.448637\n","9    1.00           3         0.445851\n","10   1.00           5         0.457845\n","11   1.00          10         0.482343"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# change the presentation into dataframe format \n","coherence_df = pd.DataFrame(coherence_values, columns=['alpha','num_topics','coherence_value'])\n","coherence_df"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hs324\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA7AAAAGECAYAAAAPycxQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA1PElEQVR4nO3de5xddX3v/9cnk5lMJvcbkJAQKEQRFAQiXuu17UF7Qau2orVI/Um1pa2nrUdO+2trPcdePefYPkrLj1ZKba0WFSq2WOzFy4GqJVBuQYGIXMag5EJCrpO5fH5/7DXJzmRmMgmzZu+11+v5YB6z12Wv9Z0Q3sx7r1tkJpIkSZIktbtZrR6AJEmSJElTYYGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVbTKiLeERG3Tve6ktTOzD5JdWYGaiZZYNXxIuI1EfHNiNgbEV+MiLWTrLs0Im6MiD0R8WhEvLVpWU9EfDoiHomIjIhXzsT4Jel4HGP2XRERGyJiICKum8FhStK083e2zmaBVUeLiOXADcBvAEuBDcDfTfKWq4ADwInA24A/i4izm5bfCvwU8N1SBixJ0+A4sm8z8D+Ba8sfnSTNCH9n61AWWB2XiLgyIr4VEbsi4v6IeMME62VE/GJEPBwRWyPiDyNi1ph1PhwRT0XEtyPitU3zL4uIbxT7eDgifvY4hvrjwMbM/FRm7gc+AJwbEWeOM9Z5wBuB38jM3Zl5K3AT8HaAzDyQmR8p5g8fx1gkVVwnZh9AZt6QmX8PbDuOfUmqiapkoL+zdTYLrI7Xt4DvBxYBvw38TUSsnGDdNwDrgfOBi4GfaVr2QuABYDnwB8BHIyKKZU8CPwIsBC4D/k9EnA8QEadExI5JvkZP/T0buHt0Z5m5pxh781HVUc8ChjPzwaZ5d0+wrqR66sTsk6SpqkoGqoNZYHVcik/1N2fmSGb+HfAQcOEEq/9+Zm7PzMeAjwCXNC17NDP/PDOHgb8CVtI4fZfM/MfM/FY2fBn4Ao3QJDMfy8zFk3z9bbH9+cDOMePZCSwYZ5zHsq6kGurQ7JOkKalQBqqDWWB1XCLipyPirtFPvIDn0vgUbTyPN71+FFjVNH3wuoTM3Fu8nF/s47UR8bWI2F7s43WT7GMiu2l8gtdsIbDrGa4rqYY6NPskaUoqlIHqYBZYHbNo3Mnyz4ErgGWZuRi4D4gJ3rKm6fUpNG4WcrR9zAE+A3wYOLHYx82j+yhOIdk9ydfbik1tBM5t2u484PRi/lgPArMjYl3TvHMnWFdSzXRw9knSUVUsA9XBLLA6HvOABLZA42J7Gp/ATeR9EbEkItYAv8Tkd8Ic1QPMKfYxVFzc/0OjC4tTSOZP8vXxYtUbgedGxBsjohf4TeCezPzm2B0W14jdAHwwIuZFxEtpXLPx16PrRMScYjsAPRHR23TNhqTO1pHZV/wss4v1uoCuIttmT2G8kuqjShno72wdzAKrY5aZ9wP/C/gq8D3gecBtk7zls8AdwF3APwIfncI+dgG/CFwPPAW8lcYdgY91rFto3Fn4Q8V2Xgi8ZXR5RPxaRHy+6S0/B8ylcQOBTwDvyczmIxYPAPuAk4FbitcTPltRUufo8Oz7f2nk2ZU0Hjuxr5gnSUC1MrDg72wdKjKz1WNQB4uIBNZl5qZWj0WSZorZJ6nOzECVySOwkiRJkqRKKK3ARsS1EfFkRNw3wfKIiD+OiE0Rcc/o850kqUrMOkl1Yd5JagdlHoG9DrhokuWvBdYVX5cDf1biWNQimRmePqIOdx1mncYw+9ShrsO80xSYgSpTaQU2M78CbJ9klYuBjxUPKf4asDgiVpY1Hkkqg1knqS7MO0ntoJXXwJ7M4Q847i/mSVInMesk1YV5J6l0rXzG23jPYRr3lsgRcTmNU1GYN2/eBWeeeWaZ45JUQXfcccfWzFzR6nGMw6yTNG3aOOtginln1kk6msmyrpUFth9Y0zS9Gtg83oqZeQ1wDcD69etzw4YN5Y9OUqVExKOtHsMEzDpJ06aNsw6mmHdmnaSjmSzrWnkK8U3ATxd3rHsRsDMzn2jheCSpDGadpLow7ySVrrQjsBHxCeCVwPKI6Ad+C+gGyMyrgZuB1wGbgL3AZWWNRZLKYtZJqgvzTlI7KK3AZuYlR1mewM+XtX9JmglmnaS6MO8ktYNWXgM7bQYHB+nv72f//v2tHsqEent7Wb16Nd3d3a0eiqSKMusk1YFZJ2kyHVFg+/v7WbBgAaeeeioR490Ar7Uyk23bttHf389pp53W6uFIqiizTlIdmHWSJtPKmzhNm/3797Ns2bK2DDmAiGDZsmVt/UmipPZn1kmqA7NO0mQ6osACbRtyo9p9fJKqod2zpN3HJ6ka2j1L2n18UifrmAIrSZIkSepsFlhJkiRJUiVYYKfRxz72Mc455xzOPfdc3v72t7d6OJJUCrNOUh2YdVJ76oi7EDf77c9t5P7NT0/rNs9atZDf+tGzJ11n48aNfOhDH+K2225j+fLlbN++fVrHIEnNzDpJdWDWSRrLI7DT5N/+7d9405vexPLlywFYunRpi0ckSdPPrJNUB2ad1L467gjs0T5RK0tmekc6STPGrJNUB2adpLE8AjtNXvOa13D99dezbds2AE81kdSRzDpJdWDWSe2r447AtsrZZ5/Nr//6r/OKV7yCrq4uzjvvPK677rpWD0uSppVZJ6kOzDqpfVlgp9Gll17KpZde2uphSFKpzDpJdWDWSe3JU4glSZIkSZVggZUkSZIkVYIFVpIkSZJUCR1TYDOz1UOYVLuPT1I1tHuWtPv4JFVDu2dJu49P6mQdUWB7e3vZtm1b24ZJZrJt2zZ6e3tbPRRJFWbWSaoDs07SZDriLsSrV6+mv7+fLVu2tHooE+rt7WX16tWtHoakCjPrJNWBWSdpMh1RYLu7uznttNNaPQxJKpVZJ6kOzDpJk+mIU4glSZIkSZ3PAitJkiRJqgQLrCRJkiSpEiywkiRJkqRKsMBKkiRJkirBAitJkiRJqgQLrCRJkiSpEiywkiRJkqRKsMBKkiRJkirBAitJkiRJqgQLrCRJkiSpEiywkiRJkqRKsMBKkiRJkirBAitJkiRJqgQLrCRJkiSpEiywkiRJkqRKsMBKkiRJkirBAitJkiRJqoRSC2xEXBQRD0TEpoi4cpzlSyLixoi4JyL+IyKeW+Z4JKkMZp2kOjDrJLWD0gpsRHQBVwGvBc4CLomIs8as9mvAXZl5DvDTwB+VNR5JKoNZJ6kOzDpJ7aLMI7AXApsy8+HMPAB8Erh4zDpnAf8KkJnfBE6NiBNLHJMkTTezTlIdmHWS2kKZBfZk4PGm6f5iXrO7gR8HiIgLgbXA6rEbiojLI2JDRGzYsmVLScOVpONi1kmqA7NOUlsos8DGOPNyzPTvAUsi4i7gF4D/BIaOeFPmNZm5PjPXr1ixYtoHKknPgFknqQ7MOkltYXaJ2+4H1jRNrwY2N6+QmU8DlwFERADfLr4kqSrMOkl1YNZJagtlHoG9HVgXEadFRA/wFuCm5hUiYnGxDOD/Ab5ShJ8kVYVZJ6kOzDpJbaG0I7CZORQRVwC3AF3AtZm5MSLeXSy/GngO8LGIGAbuB95Z1ngkqQxmnaQ6MOsktYsyTyEmM28Gbh4z7+qm118F1pU5Bkkqm1knqQ7MOkntoMxTiCVJkiRJmjYWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAmlFtiIuCgiHoiITRFx5TjLF0XE5yLi7ojYGBGXlTkeSSqDWSepDsw6Se2gtAIbEV3AVcBrgbOASyLirDGr/Txwf2aeC7wS+F8R0VPWmCRpupl1kurArJPULso8AnshsCkzH87MA8AngYvHrJPAgogIYD6wHRgqcUySNN3MOkl1YNZJagtlFtiTgcebpvuLec3+BHgOsBm4F/ilzBwpcUySNN3MOkl1YNZJagtlFtgYZ16Omf4vwF3AKuD5wJ9ExMIjNhRxeURsiIgNW7Zsme5xStIzYdZJqgOzTlJbKLPA9gNrmqZX0/hErtllwA3ZsAn4NnDm2A1l5jWZuT4z169YsaK0AUvScTDrJNWBWSepLZRZYG8H1kXEacUF/G8BbhqzzmPAawAi4kTg2cDDJY5JkqabWSepDsw6SW1hdlkbzsyhiLgCuAXoAq7NzI0R8e5i+dXA/wCui4h7aZya8v7M3FrWmCRpupl1kurArJPULkorsACZeTNw85h5Vze93gz8UJljkKSymXWS6sCsk9QOyjyFWJIkSZKkaWOBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiUctcBGw09FxG8W06dExIXlD02SZo5ZJ6kOzDpJVTeVI7B/CrwYuKSY3gVcVdqIJKk1zDpJdWDWSaq02VNY54WZeX5E/CdAZj4VET0lj0uSZppZJ6kOzDpJlTaVI7CDEdEFJEBErABGSh2VJM08s05SHZh1kiptKgX2j4EbgRMi4kPArcDvlDoqSZp5Zp2kOjDrJFXaUU8hzsyPR8QdwGuAAF6fmd8ofWSSNIPMOkl1YNZJqrqjFtiIOAXYC3yueV5mPlbmwCRpJpl1kurArJNUdVO5idM/0rhOIoBe4DTgAeDsEsclSTPNrJNUB2adpEqbyinEz2uejojzgZ8tbUSS1AJmnaQ6MOskVd1UbuJ0mMy8E3hBCWORpLZh1kmqA7NOUtVM5RrYX26anAWcD2wpbUSS1AJmnaQ6MOskVd1UroFd0PR6iMa1E58pZziS1DJmnaQ6MOskVdpUroH97ZkYiCS1klknqQ7MOklVN2GBjYjP0bhL3bgy88dKGZEkzSCzTlIdmHWSOsVkR2A//Ew3HhEXAX8EdAF/kZm/N2b5+4C3NY3lOcCKzNz+TPctSVNk1kmqA7NOUkeYsMBm5pefyYYjogu4CvhBoB+4PSJuysz7m/bxh8AfFuv/KPBfDTlJM8msk1QHZp2kTnHUx+hExLqI+HRE3B8RD49+TWHbFwKbMvPhzDwAfBK4eJL1LwE+MbVhS9L0Musk1YFZJ6nqpvIc2L8E/ozGnepeBXwM+OspvO9k4PGm6f5i3hEiog+4CO+CJ6l1zDpJdWDWSaq0qRTYuZn5r0Bk5qOZ+QHg1VN4X4wzb6KbB/wocNtEp5lExOURsSEiNmzZ4qPKJJXCrJNUB2adpEqbSoHdHxGzgIci4oqIeANwwhTe1w+saZpeDWyeYN23MMlpJpl5TWauz8z1K1asmMKuJemYmXWS6sCsk1RpExbYiDixePleoA/4ReAC4KeAS6ew7duBdRFxWkT00Aizm8bZzyLgFcBnj2nkkjQNzDpJdWDWSeoUkz1G5+6IuJfGJ2gPZmY/cNlUN5yZQxFxBXALjdutX5uZGyPi3cXyq4tV3wB8ITP3HNdPIEnPjFknqQ7MOkkdITLHv3yhuF36D9D4hO11wFdphN5NmblvxkY4xvr163PDhg2t2r2kNhURd2Tm+uN4n1knqTLMOkl1MFnWTXgKcWYOZ+YtmXkZjWse/hJ4PfDtiPh4KSOVpBlm1kmqA7NOUqeYyk2cKJ73dT/wDeBp4KwyByVJrWDWSaoDs05SlU1aYCPilIh4X0TcCfwDjWseLs7M82ZkdJI0A8w6SXVg1knqBBPexCki/p3GA6o/BVyemV6gIKnjmHWS6sCsk9QpJrsL8X8HvpIT3eVJkjqDWSepDsw6SR1hwgKbmV+eyYFIUiuYdZLqwKyT1CmmdBMnSZIkSZJazQIrSZIkSaqEoxbYiDgxIj4aEZ8vps+KiHeWPzRJmjlmnaQ6MOskVd1UjsBeB9wCrCqmHwTeW9J4JKlVrsOsk9T5rsOsk1RhUymwyzPzemAEIDOHgOFSRyVJM8+sk1QHZp2kSptKgd0TEcuABIiIFwE7Sx2VJM08s05SHZh1kiptsufAjvpl4Cbg9Ii4DVgBvKnUUUnSzDPrJNWBWSep0o5aYDPzzoh4BfBsIIAHMnOw9JFJ0gwy6yTVgVknqeqmchfinwfmZ+bGzLwPmB8RP1f+0CRp5ph1kurArJNUdVO5BvZdmbljdCIznwLeVdqIJKk1zDpJdWDWSaq0qRTYWRERoxMR0QX0lDckSWoJs05SHZh1kiptKjdxugW4PiKupnHHuncD/1TqqCRp5pl1kurArJNUaVMpsO8HfhZ4D42L/b8A/EWZg5KkFjDrJNWBWSep0qZyF+IR4M+KL0nqSGadpDow6yRV3VELbES8FPgAsLZYP4DMzO8rd2iSNHPMOkl1YNZJqrqpnEL8UeC/AncAw+UOR5JaxqyTVAdmnaRKm0qB3ZmZny99JJLUWmadpDow6yRV2lQK7Bcj4g+BG4CB0ZmZeWdpo5KkmWfWSaoDs05SpU2lwL6w+L6+aV4Cr57+4UhSy5h1kurArJNUaVO5C/GrZmIgktRKZp2kOjDrJFXdrKOtEBEnRsRHI+LzxfRZEfHO8ocmSTPHrJNUB2adpKo7aoEFrgNuAVYV0w8C7y1pPJLUKtdh1knqfNdh1kmqsKkU2OWZeT0wApCZQ3jbdUmdx6yTVAdmnaRKm0qB3RMRy2hc4E9EvAjYWeqoJGnmmXWS6sCsk1RpU7kL8S8DNwGnR8RtwArgTaWOSpJmnlknqQ7MOkmVNmmBjYgu4BXF17OBAB7IzMEZGJskzQizTlIdmHWSOsGkpxBn5jBwcWYOZebGzLzPkJPUacw6SXVg1knqBFM5hfi2iPgT4O+APaMzM/PO0kYlSTPPrJNUB2adpEqbSoF9SfH9g03zEnj19A9HklrGrJNUB2adpEo7aoHNzFfNxEAkqZXMOkl1YNZJqrqjPkYnIk6MiI9GxOeL6bMi4p3lD02SZo5ZJ6kOzDpJVTeV58BeB9wCrCqmHwTeW9J4JKlVrsOsk9T5rsOsk1RhUymwyzPzemAEIDOHgOGpbDwiLoqIByJiU0RcOcE6r4yIuyJiY0R8ecojl6TpZdZJqgOzTlKlTeUmTnsiYhmNC/yJiBcBO4/2puJZY1cBPwj0A7dHxE2ZeX/TOouBPwUuyszHIuKEY/8RJGlamHWS6sCsk1RpUymwvwzcBJweEbcBK4A3TeF9FwKbMvNhgIj4JHAxcH/TOm8FbsjMxwAy88ljGLskTSezTlIdmHWSKm0qdyG+MyJeATwbCOCBKT70+mTg8abpfuCFY9Z5FtAdEV8CFgB/lJkfG7uhiLgcuBzglFNOmcKuJenYmHWS6sCsk1R1UzkCC41P3U4t1j8/IhgvkMaIceblOPu/AHgNMBf4akR8LTMfPOxNmdcA1wCsX79+7DYkabqYdZLqwKyTVFlHLbAR8dfA6cBdHLrIP4GjBV0/sKZpejWweZx1tmbmHhrXZHwFOJfGHfEkacaYdZLqwKyTVHVTOQK7HjgrM4/1E7LbgXURcRrwHeAtNK6NaPZZ4E8iYjbQQ+NUlP9zjPuRpOlg1kmqA7NOUqVNpcDeB5wEPHEsG87MoYi4gsazxrqAazNzY0S8u1h+dWZ+IyL+CbiHxu3c/yIz7zumn0CSpodZJ6kOzDpJlRYTfQAXEZ+jcUrJAuD5wH8AA6PLM/PHZmB8R1i/fn1u2LChFbuW1MYi4o7MXH8c7zPrJFWGWSepDibLusmOwH64pPFIUjsx6yTVgVknqSNMWGAz88ujryPiROAFxeR/+FwvSZ3CrJNUB2adpE4x62grRMRP0DjN5M3ATwBfj4ipPPBakirDrJNUB2adpKqbyk2cfh14weincxGxAvgX4NNlDkySZphZJ6kOzDpJlXbUI7DArDGnlmyb4vskqUrMOkl1YNZJqrSpHIH9p4i4BfhEMf2TwOfLG5IktYRZJ6kOzDpJlXbUApuZ74uIHwdeBgRwTWbeWPrIJGkGmXWS6sCsk1R1ExbYiDgDODEzb8vMG4Abivkvj4jTM/NbMzVISSqLWSepDsw6SZ1ismsePgLsGmf+3mKZJHWCj2DWSep8H8Gsk9QBJiuwp2bmPWNnZuYG4NTSRiRJM8usk1QHZp2kjjBZge2dZNnc6R6IJLWIWSepDsw6SR1hsgJ7e0S8a+zMiHgncEd5Q5KkGWXWSaoDs05SR5jsLsTvBW6MiLdxKNjWAz3AG0oelyTNlPdi1knqfO/FrJPUASYssJn5PeAlEfEq4LnF7H/MzH+bkZFJ0gww6yTVgVknqVNM5TmwXwS+OANjkaSWMesk1YFZJ6nqJrsGVpIkSZKktmGBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVggVWkiRJklQJFlhJkiRJUiVYYCVJkiRJlWCBlSRJkiRVQqkFNiIuiogHImJTRFw5zvJXRsTOiLir+PrNMscjSWUw6yTVgVknqR3MLmvDEdEFXAX8INAP3B4RN2Xm/WNW/b+Z+SNljUOSymTWSaoDs05SuyjzCOyFwKbMfDgzDwCfBC4ucX+S1ApmnaQ6MOsktYUyC+zJwONN0/3FvLFeHBF3R8TnI+LsEscjSWUw6yTVgVknqS2UdgoxEOPMyzHTdwJrM3N3RLwO+Htg3REbirgcuBzglFNOmeZhStIzYtZJqgOzTlJbKPMIbD+wpml6NbC5eYXMfDozdxevbwa6I2L52A1l5jWZuT4z169YsaLEIUvSMTPrJNWBWSepLZRZYG8H1kXEaRHRA7wFuKl5hYg4KSKieH1hMZ5tJY5JkqabWSepDsw6SW2htFOIM3MoIq4AbgG6gGszc2NEvLtYfjXwJuA9ETEE7APekpljT0eRpLZl1kmqA7NOUruIquXK+vXrc8OGDa0ehqQ2ExF3ZOb6Vo9juph1ksZj1kmqg8myrsxTiCVJkiRJmjYWWEmSJElSJZT5GB1JkiRJUgcaHB5hx95Bduw9wPY9B3hq7wGe2jvI9j0HinmDxbwDrFzUy5++7YJp2a8FVqqQzCQTRjJJiu/FZewjY5Zljr8+jX8OXz+L9Rm7jWLZMa4/Mrrvpn2OTHH90Xmrl/TxvNWLWvHHLEmSVCuDwyONsjlaOvccYPveA+woCumheYcK6679QxNub253F0v6ulkyr4clfT2ctHDutI3VAqvjtvfAEHc9voN7+ney98AwZB4sKSPZVKBofB+dN1I0rpxo/Qm2MTKmTNFcpo6y/mFFrqlAkUeWwYnWb4x5qmXwUIk8sqwdvoxx5k20fp1ccuEafnf1Oa0ehiRJUqUMDA2zY2+jiDaOhhYldE/jCOnoUdGDJXXPILsGJi6jfT1dLOnrYcm8bpb09XDqsr7GdNO80ddLi8La291V2s9ngdWUPbFzHxseeYo7Hm183f/E0wyPHGpVERDArIjidfE9innFMkbXmxWHrQ/BrDHrR0y8jUPrFPOa9z3ONprXj9FtzQpmRzSN4dA2xl2/adnBn+OI9ePIP4tx5h0x5qY/k0Njbv5zjDF/vo31Dx/zeOs3Xs8qfpgYZ/3mP89Zsybe56zD/j0dff3RvwcH1x9nG4ePuVh/Fiye2zOtf38lSZKqZv/g8MECumNvo3A+tXewUT4Pzjt0VHTH3kF2T1JG58+ZzeK+RtFc3NfDacvnHTxK2vjezdK+xrLGOt2lltHjYYHVuIaGR/jmd3ex4ZHt3PHYDu54ZDubd+4HGqcEPH/NYt7zitO54NQlnL9mCYv6uls8YkkzafueA/zPf7ifux7fwcrFvaxcNJdVi+dyctPrVYt76evxfzOSJEGjjI4eFX1qT/OR0ENHS8fO23tgeMLtLZgz+1DpnNfD6Svms6Svh6Xzug8roKNHRRf3dTNndnuV0ePhbxYCYOe+Qf7zsUNHV+96fMfB/2BWLurlgrVLeNfaJaxfu5QzVy6gu8sbWEt19c/3f4//fsO97Nx3gFc86wS27xng1oe28uSu/YyMOdV9cV83qxY1yuyqxXOLctvLyYvnsnLxXE5cMIfZ5olqYmQk2T80zP7BEfYPDjMwNEJ3V7B6SV+rhybpGO07MNw4GlqUzuZTdcceFR09dXff4MRldGHv7INHQlfMn8OzTlxQlNHi6GjT9aRL5nWzeG4PPbPr+f9PC2wNZSaPbtvLHY8+xYZHn+LOR5/iwSd3kQlds4LnrFzAmy9YzQWnLmX92iWsWjx9F11Lqq6d+wb54Ofu5zN39vOclQv52M9cyFmrFh5cPjg8wvee3s/mHft5Yuc+vrNjH0/s2M/mHfvof2oftz/yFDv3DR62zVkBJy7sLY7YzmXVotGi21sc0Z3L4r5uYvQcf2majIwkA0OHiuT+weHDymXja4SBoWEGBkeKZc3LG/MGDn5vWjampO4fbKx3YHjkiHG86tkr+MvLLmzBn4AkaPxevPfA8OE3MDp4NHTwYEEde6R0YOjI/55HLZrbffDo50kLeznzpIWHHRUdLaSjp/Eu7uv24NAxsMDWwMDQMPd9Z2ejsD7yFHc+9hRbdx8AYEHvbM4/ZQk/fM5K1q9dwrlrFjNvjn8tJB3uKw9u4f2fuYcndw3wC68+g1949bojPvnt7prF6iV9kx5N2jMwVJTbRrF9Ykfj9RM793Fv/w5u2bifA2N+KejtnlWU20NHclcVpymvXNzLqkVzmdtT/VOi6iyzUSbHL4rD7B8aWwaPLIsDQ4eXy4Ex2zlYUovtjf17dixmzwrmzJ5Fb3cXvd1dzOmeRe/sLnq7G/MWzu1uWj6LObO7Dr7u7e46bNmqRX5ILE2XzGTPgeFJjooeXkJ37B1k+94DE+ZBRFFGi+tDVy3u5exVCw8dCS2Oii4tTuNd0tfDorndnllUMptKB9q6e4A7iiOrGx59inv7dx781Hftsj5e/qwVXFCcDrzuhPkHbwQkSWPtGRjid27+Bh//+mOcvmIeN7znJZy7ZvFxb2/enNmcccICzjhhwbjLM5Ntew6wecc+Nhcld/OOfTyxcz/f2bGPLz2whS27B464K/fSeT0Hj9qOHsUdvQ531eK5nLCgly6zbkoykwPDI40S2HSkcbIyODDmiOWhcnlovYExRyzHbu94zQoOFsneohjOGS2Ls7tYNn/2YeXy8MJ5eJnsbXrfnHGXNfbhL6dS+TKT3QNDhwrn3qa76DYdFT28pA6Oe6YDNLJi9Gjn0r4e1izt45zVh07LXdp0E6PReYvmdvv/jjZkga24kZFk05bdTXcH3s4j2/YC0NM1i+eevJB3vPRUzj9lCResXcKKBXNaPGJJVfG1h7fxvk/fTf9T+3jX95/Gr/zQs0u/E2FEsHz+HJbPn8M5q8df58DQ6KnK+9i88/Ci+/j2vXzt4W1HPJuua1Zw0sJeVk1yw6lFc9vvVOXMZHA4Dxa+gfFOXx3n1NeB0VI5dPjpsGOPZjYXz4P7GBo57sd2RXBkWWwqgY1HKxTTTevNOexI5aFy2VwqR5eNPZrpaXdS+8tMnt4/dNidcrcfVkKbrhct7rK7Y+8BBofHD6OuWcHiud0HC+cpS/t4/prFxSm6xam6zXfVndfDwt5uD9p0CAtsxYw+e/XOputXny5+UVs2r4fz1y7hkgtP4YK1S3juyYva7rbXktrf/sFh/uCfHuAv//3brFnSx/U/+2JecOrSVg/roJ7Zs1iztI81Syc+VXnX/sGDR203N12Lu3nnPu56fAefv++JI34x6uvpOnj97cnj3HBq5aLGUdzDjxyOf/rqeNdBjlcWx753YEzhHBgaPuLGWMdiwrI4exaL5nbTu2DOuEcYDz/6eGSpnHPY9g7to7sr2u5DAEnTa2Qk2bV/qHicy+FHRbfvPdBURA8dKd2xd5ChCcKsa1Ycdjru9y2fP+bZok2n6hbzFvTOtozWmAW2zU327NV1J8znh89ZyfmnLGH9qUs5dVmfvzhIekb+87Gn+JVP3c3DW/bw9het5crXnlnJ6+IX9HazoLebZ504/qnKIyPJ1j0DjRtO7dhXFN3Gtbibd+zjG0/sYuvugWkd0xGno44eUezuYkHvbFaMlskx682ZfXjxbC6VzUWyeXu93bPo6Zrl/xMkHdXwSLJ9zwG27Bpgy+4BtuwaYPueAbbvGXMDo6KQ7tg3ePB30bG6u+Lg0c/Ffd2cccL8QwW0KJ+HPdplXg8L5sw2q3RMqvdbSQc72rNXz12zqPHs1bVLOP8Un70qafoMDA3zR//yEFd/+VuctLCXv3nnC3nZuuWtHlZpZs0KTljQywkLenn+BNf0DgwN892d+w+eovzEzn1kcqg8jr3ucuwRy6JUzumexZzZlklJM2f0lN0tuwYOK6bN01uL79t2D4x7pkdP16zDjoQ+68T5TQV0zKm6xaNd5ltGNQMssC002bNXT1rYywWnNp69esHaJTxn5UKv85FUio2bd/Ir19/NN7+7izdfsJrf+NGzWNjrB2RzZnexdtk81i6b1+qhSBLQuMRjokI6dnq8O+t2dwUr5s9hxYI5rFrcy7lrFh2cHv0avQ9BX0+XZVRtyQI7QyZ79uqsgLNWLTz47NUL1i7hZJ+9Kqlkg8Mj/NmXvsUf/+tDLJnXw0cvXc9rnnNiq4clSbUyNDzC9j0HeHLXAFt3T1xIt+waOOIGddC4edqyeT0sL4ro962Y1yijo8W0qaC2483qpGNlgS1J49mrT3PHo9uLI6w7Dl5P5bNXJbXaQ9/bxa986m7u6d/Jj567ig/+2NksmdfT6mFJ0oR2Dwyxa/8gfd2zmdvTdcSzqNtJZvL0viG27N7Pk5McKd26e4Btew6Me+fvBXMa18YvXzCH56xcyMvXHX6kdMX8OZywYA5L5/X4aCfViq1pmgwOj3BP/w5ufWgbt23ayl39Ow6eutF49upyn70qqeWGR5KP3vowH/7Cg8zr6eKqt57PD5+zstXDkqSjuumuzfzajfcenJ49K5jb00VfTxfzemYffD23ZzZ93aOvG9/7emYX34vlo8u6u5g359B7j1aO9x0YZuvugUOldKJrS3cNjPs80p6uWQdL6eolfZx3ypLDCumKBY1Sunz+HOb2+CQJaTwW2OOUmTz05G5ufWgrt23aytce3saeA8NEwHNXLeLSF6/lgrVLffaqpLbxyNY9/Oqn7mbDo0/xg2edyO+84Xnmk6TKuPC0pfzujz+PvQeG2TswxN7BYfYdGGbvgSH2Hhh9PczOfYN8d+c+9gwMs2+wsXz/4JFlcjKj5XheUXYT2LprgF0DRz+F9/Sxp/AWpXTF/F4WzvUmR9IzZYE9Bpt37OO2TY3Cetu3trFlV+OU4FOX9fH6807mZWcs58WnL2Nxn6fhSWofIyPJ33z9UX735m8yuyv43z9xLm8472R/iZJUKWecMJ8zTph/XO8dGcmizBZFd3CoUXCLAjy6rLF86ODr0XKccMTNjjyFV2oNC+wkdu4d5KsPb+W2TY3Tgh/eugeA5fN7eMnpy3nZGct5yRnLWL2kr8UjlaTxfWfHPv7bp+/mtk3bePmzVvD7b3weKxd5kzhJ9TJrVjBvzmzvOSJ1AP8rbrJ/cJg7Hn3q4FHWe7+zk5GEvp4uXnjaUt76wlN42brlPPvEBR65kNTWMpNPbejng/9wP5nJ77zheVxy4RqzS5IkVVqtC+zwSLJx805u3bSVf9+0jdsf2c7A0AizZwXnnbKYX3j1Ol62bjnnrl7c1ne6k6Rm33t6P1d+5h6++MAWXnjaUj785nNZs9QzRSRJUvXVqsBmJo9s28utm7Zy20Nb+erD29i5bxCAM09awE+9aC0vO2M5LzhtKfM9xURSxWQmN929md/87Eb2Dw7zmz9yFu94yane9VySJHWMjm9pT+7az1e/te3g3YI379wPwMmL5/Jfzj6Rl56xnJecvtw7cUqqtG27B/iNz97Hzfd+l/NOWcyH33wup684vpudSJIktauOLrC/duO9/O3XHwNg0dxuXnL6Mn7uVY2bL61d1ue1YJI6wr/c/z3e/5l7eHr/IP/tomdz+fd/n3fElCRJHamjC+zLzljOmiV9vOyM5Zy1aiFdnkYnqQNt3T3ASYt6+fi7XsiZJy1s9XAkSZJK09EF9nXPW9nqIUhS6X7yBWt44wWr6faoqyRJ6nAdXWAlqQ4igu4uzzCRJEmdz4/rJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJZRaYCPiooh4ICI2RcSVk6z3gogYjog3lTkeSSqDWSepDsw6Se2gtAIbEV3AVcBrgbOASyLirAnW+33glrLGIkllMesk1YFZJ6ldlHkE9kJgU2Y+nJkHgE8CF4+z3i8AnwGeLHEsklQWs05SHZh1ktpCmQX2ZODxpun+Yt5BEXEy8Abg6sk2FBGXR8SGiNiwZcuWaR+oJD0DZp2kOjDrJLWFMgtsjDMvx0x/BHh/Zg5PtqHMvCYz12fm+hUrVkzX+CRpOph1kurArJPUFmaXuO1+YE3T9Gpg85h11gOfjAiA5cDrImIoM/++xHFJ0nQy6yTVgVknqS2UWWBvB9ZFxGnAd4C3AG9tXiEzTxt9HRHXAf9gyEmqGLNOUh2YdZLaQmkFNjOHIuIKGneh6wKuzcyNEfHuYvmk10dIUhWYdZLqwKyT1C7KPAJLZt4M3Dxm3rgBl5nvKHMsklQWs05SHZh1ktpBmTdxkiRJkiRp2lhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJZRaYCPiooh4ICI2RcSV4yy/OCLuiYi7ImJDRLyszPFIUhnMOkl1YNZJagezy9pwRHQBVwE/CPQDt0fETZl5f9Nq/wrclJkZEecA1wNnljUmSZpuZp2kOjDrJLWLMo/AXghsysyHM/MA8Eng4uYVMnN3ZmYxOQ9IJKlazDpJdWDWSWoLZRbYk4HHm6b7i3mHiYg3RMQ3gX8EfqbE8UhSGcw6SXVg1klqC6WdQgzEOPOO+CQuM28EboyIlwP/A/iBIzYUcTlweTG5OyIeOIZxLAe2HsP606VV+22Vuv28Kt+x/p1aW9ZAjsKsq9d/+3X7eVU+s86sa0d1+3lVvmnLujILbD+wpml6NbB5opUz8ysRcXpELM/MrWOWXQNcczyDiIgNmbn+eN77TLRqv61St59X5avQ3ymzrhr/nqZF3X5ela9Cf6fMumr8e5oWdft5Vb7p/DtV5inEtwPrIuK0iOgB3gLc1LxCRJwREVG8Ph/oAbaVOCZJmm5mnaQ6MOsktYXSjsBm5lBEXAHcAnQB12bmxoh4d7H8auCNwE9HxCCwD/jJpov/JantmXWS6sCsk9QuotNzJSIuL05VqcV+W6VuP6/K59+pY2PWzYy6/bwqn3+njo1ZNzPq9vOqfNP5d6rjC6wkSZIkqTOUeQ2sJEmSJEnTpmMLbESsiYgvRsQ3ImJjRPzSDO23NyL+IyLuLvb72zOx31aJiEci4t6IuCsiNrR6PKqmiLg2Ip6MiPua5i2NiH+OiIeK70taOcZ2ZdbNDLNO08GsO35m3cww6zQdys66jj2FOCJWAisz886IWADcAbw+M+8veb8BzMvM3RHRDdwK/FJmfq3M/bZKRDwCrB97i3zpWETjeYG7gY9l5nOLeX8AbM/M34uIK4Elmfn+Vo6zHZl1M8Os03Qw646fWTczzDpNh7KzrmOPwGbmE5l5Z/F6F/AN4OQZ2G9m5u5isrv46sxPCaRpkplfAbaPmX0x8FfF678CXj+TY6oKs06qDrPu+Jl1UnWUnXUdW2CbRcSpwHnA12dof10RcRfwJPDPmTkj+22RBL4QEXdExOWtHow6yomZ+QQ0fnEBTmjxeNqeWVcqs05lMeuOkVlXKrNOZZm2rCvtObDtIiLmA58B3puZT8/EPjNzGHh+RCwGboyI52bmfUd5W1W9NDM3R8QJwD9HxDeLT10kzSCzrnRmndQGzLrSmXVqex19BLa4VuEzwMcz84aZ3n9m7gC+BFw00/ueKZm5ufj+JHAjcGFrR6QO8r3imqfRa5+ebPF42pZZVz6zTiUy66bIrCufWacSTVvWdWyBLS66/yjwjcz83zO43xXFJ3RExFzgB4BvztT+Z1JEzCtupEBEzAN+COjUTyQ1824CLi1eXwp8toVjaVtmXfnMOpXMrJsCs658Zp1KNm1Z18l3IX4Z8H+Be4GRYvavZebNJe/3HBoXJnfR+IDg+sz8YJn7bJWI+D4an85B43T0v83MD7VwSKqoiPgE8EpgOfA94LeAvweuB04BHgPenJljbwhQe2Zd+cw6TRez7viZdeUz6zRdys66ji2wkiRJkqTO0rGnEEuSJEmSOosFVpIkSZJUCRZYSZIkSVIlWGAlSZIkSZVggZUkSZIkVYIFVpIkSZJUCRZYVVZEvCMiVj2D9787In56OsckSdPNrJNUB2adpsrnwKqyIuJLwK9m5oZWj0WSymLWSaoDs05T5RFYTauIODUivhERfx4RGyPiCxExNyK+FBHri3WWR8Qjxet3RMTfR8TnIuLbEXFFRPxyRPxnRHwtIpZOsJ83AeuBj0fEXcU+XlO8796IuDYi5hTrPhIRvx8R/1F8nVHM/0BE/Grx+oyI+JeIuDsi7oyI0yNiZUR8pdj+fRHx/TPwRyipAsw6SXVg1qkdWWBVhnXAVZl5NrADeONR1n8u8FbgQuBDwN7MPA/4KjDuqSCZ+WlgA/C2zHw+kMB1wE9m5vOA2cB7mt7ydGZeCPwJ8JFxNvnxYsznAi8BnijGdEux/XOBu47yc0iqF7NOUh2YdWorFliV4duZeVfx+g7g1KOs/8XM3JWZW4CdwOeK+fdO4b2jnl3s98Fi+q+Alzct/0TT9xc3vzEiFgAnZ+aNAJm5PzP3ArcDl0XEB4DnZeauKY5FUj2YdZLqwKxTW7HAqgwDTa+HaXxqNsShv2+9k6w/0jQ9Urx3KuIoy3OC1xO+NzO/QiMsvwP8dXhjAEmHM+sk1YFZp7ZigdVMeQS4oHj9pmna5i5gQfH6m8Cpo9dBAG8Hvty07k82ff9q80Yy82mgPyJeDxARcyKiLyLWAk9m5p8DHwXOn6ZxS+pcj2DWSep8j2DWqUWm+imI9Ex9GLg+It4O/Ns0bfM64OqI2Efj9JHLgE9FxGwap4lc3bTunIj4Oo0PbS4ZZ1tvB/6/iPggMAi8Gfh+4H0RMQjsZoLrNiSpiVknqQ7MOrWMj9FRxyvujLc+M7e2eiySVBazTlIdmHXyFGJJkiRJUiV4BFZtLyKuAl46ZvYfZeZftmI8klQGs05SHZh1eqYssJIkSZKkSvAUYkmSJElSJVhgJUmSJEmVYIGVJEmSJFWCBVaSJEmSVAkWWEmSJElSJfz/56uSwCjoYzMAAAAASUVORK5CYII=","text/plain":["<Figure size 1152x432 with 3 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["def plot_coherence(coherence_df,alpha_range,num_topics_range):\n","    \"\"\"\n","    Came up with the plots that shows the change of coherence score given different combination of alpha and number of topics. \n","    \"\"\"\n","    plt.figure(figsize=(16,6))\n","    for i,val in enumerate(alpha_range):\n","        # index is the index of alpha \n","        plt.subplot(1,3,i+1)\n","        alpha_subset=coherence_df[coherence_df['alpha']==val]\n","        plt.plot(alpha_subset['num_topics'],alpha_subset['coherence_value'])\n","        plt.xlabel('num_topics')\n","        plt.ylabel('Coherence Value')\n","        plt.title('alpha={0}'.format(val))\n","        plt.ylim([0.30,1])\n","        plt.legend('coherence value', loc='upper left')\n","        plt.xticks(num_topics_range)\n","\n","plot_coherence(coherence_df,alpha_range,num_topics_range)"]},{"cell_type":"markdown","metadata":{},"source":["__*Analysis for the Optimal Number of Topics*__<br><br>\n","From the above subplots, we can see that when setting alpha as 0.01, we reaches the highest coherence value at the number of topic being 5, when alpha being set as 0.1, the optimal number of topics is 3, while when alpha being 1, the coherence value is showing a slightly upwards patteren without a turning point. This is likely because when the alpha is going higher, the weight is much more evenly distributed across the topics.<br>\n","\n","In combination with the previous viz of LDA result, we would go with the defalut alpha(0.1) and choose 3 as number of topic. "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"“Unsupervised Learning Project.ipynb”的副本","provenance":[{"file_id":"1O6KOwKbLyWnV0STGrtaC-8iELjogAWh9","timestamp":1658802183133},{"file_id":"1_xgqsVSDqV7AO4qhPAMohLs2lDm10nSL","timestamp":1611278396693},{"file_id":"1w1y1zHU61ttbdEwU5ns3RPuhdwHprWLC","timestamp":1598230107932},{"file_id":"1wq_QmwTmSvy3HhmlfjkNvGR_QEu2QN5i","timestamp":1594196118473}]},"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"vscode":{"interpreter":{"hash":"22f19ce86b3867e446285b3f1a72227a98aa5a90743b2ef78c9d35e67c033ac6"}}},"nbformat":4,"nbformat_minor":0}
